{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f086adc4-3c4e-4125-87ac-07518cb1771f",
   "metadata": {},
   "source": [
    "## Performing basic exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3b3beb6-2c71-4fcc-b62f-87e382047a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  energy_cost  gov_policy_score  demand_index  hydrogen_price\n",
      "0  2018-01-07    54.967142                 9      1.043502       43.186452\n",
      "1  2018-01-14    48.617357                 1      1.389174       54.617608\n",
      "2  2018-01-21    56.476885                10      1.138324       43.624159\n",
      "3  2018-01-28    65.230299                 7      1.257230       58.005063\n",
      "4  2018-02-04    47.658466                10      1.160961       38.662031\n",
      "shape:  (500, 5)\n",
      "columns:  Index(['date', 'energy_cost', 'gov_policy_score', 'demand_index',\n",
      "       'hydrogen_price'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   date              500 non-null    object \n",
      " 1   energy_cost       500 non-null    float64\n",
      " 2   gov_policy_score  500 non-null    int64  \n",
      " 3   demand_index      500 non-null    float64\n",
      " 4   hydrogen_price    500 non-null    float64\n",
      "dtypes: float64(3), int64(1), object(1)\n",
      "memory usage: 19.7+ KB\n",
      "None\n",
      "       energy_cost  gov_policy_score  demand_index  hydrogen_price\n",
      "count   500.000000        500.000000    500.000000      500.000000\n",
      "mean     50.068380          4.912000      1.021888       44.439542\n",
      "std       9.812532          3.166118      0.211544        7.104472\n",
      "min      17.587327          0.000000      0.478032       23.628515\n",
      "25%      42.996926          2.000000      0.879216       39.921450\n",
      "50%      50.127971          5.000000      1.013622       44.499490\n",
      "75%      56.367833          7.250000      1.165179       49.556006\n",
      "max      88.527315         10.000000      1.633474       64.980409\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/hydrogen_prices.csv\")\n",
    "print(df.head())\n",
    "print(\"shape: \", df.shape)\n",
    "print(\"columns: \", df.columns)\n",
    "print(df.info())\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abed116-caea-4bc9-aa7f-55781c2e7a51",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8096bc40-eba9-4759-a5c4-4fa0dd82190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    X = df.drop(columns=[\"date\", \"hydrogen_price\"])\n",
    "    y = df[\"hydrogen_price\"]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, y, scaler\n",
    "\n",
    "# Train and evaluate multiple models\n",
    "def evaluate_models(X_train, y_train, X_test, y_test):\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "        \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        rmse = mean_squared_error(y_test, preds)\n",
    "        r2 = r2_score(y_test, preds)\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"MAE\": mae,\n",
    "            \"RMSE\": rmse,\n",
    "            \"R2 Score\": r2\n",
    "        })\n",
    "    return pd.DataFrame(results).sort_values(by=\"RMSE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5506e929-ea12-454f-9323-3b9d13953a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Comparison Results:\n",
      "\n",
      "            Model      MAE      RMSE  R2 Score\n",
      "Linear Regression 1.564802  4.086336  0.912695\n",
      "    Random Forest 1.909152  5.870342  0.874580\n",
      "    Decision Tree 2.706089 14.249002  0.695569\n"
     ]
    }
   ],
   "source": [
    "X, y, scaler = load_data(\"../data/hydrogen_prices.csv\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "results_df = evaluate_models(X_train, y_train, X_test, y_test)\n",
    "print(\"\\nModel Comparison Results:\\n\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85932a3-aded-421d-b1e3-00bc15989810",
   "metadata": {},
   "source": [
    "### Model Analysis\n",
    "\n",
    "- Linear Regression performed the best overall with the lowest MAE and RMSE, and the highest RÂ² score. This indicates that a simple linear model is effective at capturing the relationships in the data.\n",
    "- Random Forest offered reasonable performance, but slightly underperformed compared to linear regression. It may be overfitting or not benefiting as much from the dataset size or feature simplicity.\n",
    "- Decision Tree performed the worst, showing signs of overfitting (low bias, high variance), which is reflected in the high RMSE and low R2 score.\n",
    "\n",
    "#### Conclusion\n",
    "Linear Regression was chosen for deployment due to its strong performance, simplicity, and interpretability.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
